################### Mock Exam -3 #################

1) Create a new service account with the name "pvviewer". 

Grant this Service account access to list all PersistentVolumes in the cluster by creating an appropriate cluster role called "pvviewer-role" and ClusterRoleBinding called pvviewer-role-binding.

Next, create a pod called pvviewer with the image: redis and serviceAccount: pvviewer in the default namespace

----------------------------------------------------------------------------------

# kubectl create serviceaccount pvviewer

# kubectl create clusterrole pvviewer-role --resource=persistentvolumes --verb=list

# kubectl create clusterrolebinding pvviewer-role-binding --clusterrole=pvviewer-role --serviceaccount=default:pvviewer

# kubectl run pvviewer --image=redis $do > pod.yaml

-----
spec:
  containers:
  - image: redis
    name: pvviewer
  serviceAccountName: pvviewer
-----
----------------------------------------------------------------------------------




2) List the InternalIP of all nodes of the cluster. Save the result to a file /root/node_ips

Answer should be in the format: 

InternalIP of master	InternalIP of node1		InternalIP of node2		InternalIP of node3


----- cheatsheet

# kubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type=="InternalIP")].address}'  >  /root/node_ips





3) Create a pod called multi-pod with two containers. 
Container 1, name: alpha, image: nginx
Container 2: beta, image: busybox, command sleep 4800. 

Environment Variables:
container 1:
name: alpha

Container 2:
name: beta

----------------------------------------------------------------------------------
# kubectl run alpha --image=nginx $do > multi-pod.yaml

-----
metadata:
  name: multi-pod
spec:
  containers:
  - image: nginx
    name: alpha
    env:
    - name: name
      value: alpha
  - image: busybox
    name: beta
    command: ["sleep", "4800"]
    env:
    - name: beta
      value: beta
-----





3.5) Create a Pod called "lion" with image redis:alpine. Set the CPU Limit to 2 CPU and Memory Limit to 500MiB

-- search : resource limits in kubernetes docs

-----
metadata:
  name: lion
spec:
  containers:
  - name: lion
    image: redis:alpine
    resources:
      limits:
        memory: "500Mi"
        cpu: "2"
-----




4) Create a Pod called non-root-pod , image: redis:alpine
runAsUser: 1000
fsGroup: 2000







5) We have deployed a new pod called np-test-1 and a service called np-test-service. Incoming connections to this service are not working. Troubleshoot and fix it.
Create NetworkPolicy, by the name ingress-to-nptest that allows incoming connections to the service over port 80

Important: Don't delete any current objects deployed.

-------
- check the labels first
- check connectivity using busybox

	# kubectl run test-np --image=busybox:1.28 -- sh
	/ # nc -z -v -w 2 np-test-service 80


	# kubectl get netpol
	# kubectl describe netpol default-deny

	-- search: NetworkPolicy

	---------------------
	apiVersion: networking.k8s.io/v1
	kind: NetworkPolicy
	metadata:
	  name: ingress-to-nptest
	  namespace: default
	spec:
	  podSelector:
	    matchLabels:
	      run: np-test-1 			<<<< get it from #kp
	  policyTypes:
	  - Ingress
	  ingress:
	  - ports: 						<<<< no from filed as all pods are allowed
	    - protocol: TCP
	      port: 80
	---------------------

	# kubectl run test-np --image=busybox:1.28 -- sh
	/ # nc -z -v -w 2 np-test-service 80	





6) Taint the worker node node01 to be Unschedulable. Once done, create a pod called dev-redis, image redis:alpine to ensure workloads are not scheduled to this worker node. Finally, create a new pod called prod-redis and image redis:alpine with toleration to be scheduled on node01.


key:env_type, value:production, operator: Equal and effect:NoSchedule

-------

# kubectl taint node node01 env_type=production:NoSchedule
# kubectl describe node node01 | grep -i taint

# kubectl run dev-redis --image=redis:alpine 
# kp

	---------------------
metadata:
  name: prod-redis
spec:
  containers:
  - image: redis:alpine
    name: prod-redis
  tolerations:
  - effect: NoScheduler
    key: env_type
    operator: Equal
    value: production
	---------------------



7) Create a pod called hr-pod in hr namespace belonging to the production environment and frontend tier .
image: redis:alpine

Use appropriate labels and create all the required objects if it does not exist in the system already.

# kubectl create ns hr
# kubectl run hr-pod --image=redis:alpine -l environment=production,tier=frontend -n hr





8) A kubeconfig file called super.kubeconfig has been created in /root. There is something wrong with the configuration. Troubleshoot and fix it.


# kubectl cluster-info --kubeconfig=/root/super.kubeconfig

- replace port 2379 by 6443






9) We have created a new deployment called nginx-deploy. scale the deployment to 3 replicas. Has the replica's increased? Troubleshoot the issue and fix it.


# kubectl scale deployment nginx-deploy --replicas=3

# kubectl describe deployment nginx-deploy

# kubectl get pods -n kube-system

# vim /etc/kubernetes/manifest/controller-manager-master.yaml
		- check the image name

		# sed -i 's/kube-contro1ler-manager/kube-contro1ler-manager/g' kube-controller-manager.yaml

# kubectl get deployments
# kubectl get pods